{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as numpy\n",
    "from sklearn import model_selection, metrics, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/MovieLens/ratings.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.userId.nunique(), df.movieId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieDataset(Dataset):\n",
    "    def __init__(self, users, movies, ratings):\n",
    "        self.users = users\n",
    "        self.movies = movies\n",
    "        self.ratings = ratings\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        users = self.users[item]\n",
    "        movies = self.movies[item]\n",
    "        ratings = self.ratings[item]\n",
    "        \n",
    "        return {\n",
    "            \"users\": torch.tensor(users, dtype=torch.long),\n",
    "            \"movies\": torch.tensor(movies, dtype=torch.long),\n",
    "            \"ratings\": torch.tensor(ratings, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecSysModel(nn.Module):\n",
    "    def __init__(self, n_users, n_movies):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.user_embed = nn.Embedding(n_users, 32)\n",
    "        self.movie_embed = nn.Embedding(n_movies, 32)\n",
    "        self.out = nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, users, movies, ratings=None):\n",
    "        user_embeds = self.user_embed(users)\n",
    "        movie_embeds = self.movie_embed(movies)\n",
    "        return self.out(torch.cat([user_embeds, movie_embeds], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_user = preprocessing.LabelEncoder()\n",
    "lbl_movie = preprocessing.LabelEncoder()\n",
    "\n",
    "df.userId = lbl_user.fit_transform(df.userId.values)\n",
    "df.movieId = lbl_movie.fit_transform(df.movieId.values)\n",
    "\n",
    "df_train, df_test = train_test_split(\n",
    "    df, test_size=0.1, random_state=42, stratify=df.rating.values\n",
    ")\n",
    "\n",
    "print(df_train.userId.values, df_train.movieId.values, df_train.rating.values)\n",
    "\n",
    "train_dataset = MovieDataset(\n",
    "    users=df_train.userId.values,\n",
    "    movies=df_train.movieId.values,\n",
    "    ratings=df_train.rating.values\n",
    ")\n",
    "\n",
    "test_dataset = MovieDataset(\n",
    "    users=df_test.userId.values,\n",
    "    movies=df_test.movieId.values,\n",
    "    ratings=df_test.rating.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "dataloader_data = next(iter(train_loader))\n",
    "dataloader_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = RecSysModel(\n",
    "    n_users=len(lbl_user.classes_),\n",
    "    n_movies=len(lbl_movie.classes_)\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "sch = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.7)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(lbl_user.classes_))\n",
    "print(len(lbl_movie.classes_))\n",
    "print(df.movieId.max())\n",
    "print(len(train_dataset)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually run a forward path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataloader_data['users'])\n",
    "print(dataloader_data['users'].size())\n",
    "print(dataloader_data['movies'])\n",
    "print(dataloader_data['movies'].size())\n",
    "\n",
    "user_embed = nn.Embedding(len(lbl_user.classes_), 32)\n",
    "movie_embed = nn.Embedding(len(lbl_movie.classes_), 32)\n",
    "\n",
    "out = nn.Linear(64, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeds = user_embed(dataloader_data['users'])\n",
    "movie_embeds = movie_embed(dataloader_data['movies'])\n",
    "\n",
    "print(f'user_embeds {user_embeds.size()}')\n",
    "print(f'user_embeds {user_embeds}')\n",
    "print(f'movie_embeds {movie_embeds.size()}')\n",
    "print(f'movie_embeds {movie_embeds}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = torch.cat([user_embeds, movie_embeds], dim=1)\n",
    "print(f'output: {output.size()}')\n",
    "print(f'output: {output}')\n",
    "output = out(output)\n",
    "print(f'output: {output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    model_output = model(dataloader_data['users'].to(device), dataloader_data['movies'].to(device))\n",
    "    print(f'model_output: {model_output}, size: {model_output.size()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = dataloader_data['ratings']\n",
    "\n",
    "print(rating)\n",
    "print(rating.view(4, -1))\n",
    "print(model_output)\n",
    "\n",
    "print(rating.sum())\n",
    "print(model_output.sum() - rating.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "total_loss = 0\n",
    "plot_steps, print_steps = 5000, 5000\n",
    "step_cnt = 0\n",
    "all_losses_list = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    for i, train_data in enumerate(train_loader):\n",
    "        train_data[\"users\"] = train_data[\"users\"].to(device)\n",
    "        train_data[\"movies\"] = train_data[\"movies\"].to(device)\n",
    "        train_data[\"ratings\"] = train_data[\"ratings\"].to(device)\n",
    "        output = model(train_data[\"users\"], train_data[\"movies\"])\n",
    "        \n",
    "        rating = train_data[\"ratings\"].view(4, -1).to(torch.float32)\n",
    "        \n",
    "        loss = loss_fn(output, rating)\n",
    "        total_loss += loss.sum().item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        step_cnt += len(train_data[\"users\"])\n",
    "        if (step_cnt % plot_steps == 0):\n",
    "            avg_loss = total_loss / (len(train_data[\"users\"]) * plot_steps)\n",
    "            print(f'epoch {epoch} loss at step: {step_cnt} is {avg_loss}')\n",
    "            all_losses_list.append(avg_loss)\n",
    "            total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(obj=model.state_dict(), f=\"models/movielens_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f=\"models/movielens_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(all_losses_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_list = []\n",
    "target_rating_list = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for i, test_data in enumerate(test_loader):\n",
    "        users = test_data['users'].to(device)\n",
    "        movies = test_data['movies'].to(device)\n",
    "        ratings = test_data['ratings'].to(device)\n",
    "        \n",
    "        model_output = model(users, movies)\n",
    "        \n",
    "        model_output_list.append(model_output.sum().item() / len(users))\n",
    "        target_rating_list.append(ratings.sum().item() / len(users))\n",
    "        \n",
    "        print(f'Model output: {model_output}, target rating: {ratings}')\n",
    "        \n",
    "rms = mean_squared_error(target_rating_list, model_output_list, squared=False)\n",
    "print(f\"rms: {rms}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_est_true = defaultdict(list)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for i, test_data in enumerate(test_loader):\n",
    "        users = test_data['users'].to(device)\n",
    "        movies = test_data['movies'].to(device)\n",
    "        ratings = test_data['ratings'].to(device)\n",
    "        \n",
    "        model_output = model(users, movies)\n",
    "        \n",
    "        for i in range(len(users)):\n",
    "            user_id = users[i].item()\n",
    "            movie_id = movies[i].item()\n",
    "            pred_rating = model_output[i][0].item()\n",
    "            true_rating = ratings[i].item()\n",
    "            \n",
    "            print(f'User {user_id} and Movie {movie_id}:')\n",
    "            print(f'Prediction: {pred_rating}, True: {true_rating}')\n",
    "            user_est_true[user_id].append((pred_rating, true_rating))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    \n",
    "    k = 100\n",
    "    threshold = 3.5\n",
    "    \n",
    "    for user_id, user_ratings in user_est_true.items():\n",
    "        \n",
    "        # sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        \n",
    "        # get the number of actual relevant item\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "        \n",
    "        # get the number of recommended items that are predicted relevant within topk\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "        \n",
    "        # get the number of recommended items that are actually relevant within topk\n",
    "        n_rel_and_rec_k = sum(\n",
    "            ((true_r >= threshold) and (est >= threshold))\n",
    "            for (est, true_r) in user_ratings[:k]\n",
    "        )\n",
    "        print(f'User {user_id}, n_rel {n_rel}, n_rec_k {n_rec_k}, n_rel_and_rec_k {n_rel_and_rec_k}')\n",
    "        \n",
    "        precisions[user_id] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "        recalls[user_id] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'precision at {k}: {sum(prec for prec in precisions.values()) / len(precisions)}')\n",
    "print(f'recall @ {k}: {sum(rec for rec in recalls.values()) / len(recalls)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
