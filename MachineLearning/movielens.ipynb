{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as numpy\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/MovieLens/ratings.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.userId.nunique(), df.movieId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieDataset(Dataset):\n",
    "    def __init__(self, users, movies, ratings):\n",
    "        self.users = users\n",
    "        self.movies = movies\n",
    "        self.ratings = ratings\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        users = self.users[item]\n",
    "        movies = self.movies[item]\n",
    "        ratings = self.ratings[item]\n",
    "        \n",
    "        return {\n",
    "            \"users\": torch.tensor(users, dtype=torch.long),\n",
    "            \"movies\": torch.tensor(movies, dtype=torch.long),\n",
    "            \"ratings\": torch.tensor(ratings, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecSysModel(nn.Module):\n",
    "    def __init__(self, n_users, n_movies):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.user_embed = nn.Embedding(n_users, 32)\n",
    "        self.movie_embed = nn.Embedding(n_movies, 32)\n",
    "        self.out = nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, users, movies, ratings=None):\n",
    "        user_embeds = self.user_embed(users)\n",
    "        movie_embeds = self.movie_embed(movies)\n",
    "        return self.out(torch.cat([user_embeds, movie_embeds], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_user = preprocessing.LabelEncoder()\n",
    "lbl_movie = preprocessing.LabelEncoder()\n",
    "\n",
    "df.userId = lbl_user.fit_transform(df.userId.values)\n",
    "df.movieId = lbl_movie.fit_transform(df.movieId.values)\n",
    "\n",
    "BATCH_SIZE = 28\n",
    "NUM_SPLITS = 5\n",
    "\n",
    "dataset = MovieDataset(\n",
    "    users=df.userId.values,\n",
    "    movies=df.movieId.values,\n",
    "    ratings=df.rating.values\n",
    ")\n",
    "kfold = KFold(n_splits=NUM_SPLITS, shuffle=True)\n",
    "\n",
    "train_dataloaders = []\n",
    "test_dataloaders = []\n",
    "\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "    train_subsampler = SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = SubsetRandomSampler(test_ids)\n",
    "    \n",
    "    train_dataloaders.append(DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_subsampler, drop_last=True))\n",
    "    test_dataloaders.append(DataLoader(dataset, batch_size=BATCH_SIZE, sampler=test_subsampler, drop_last=True))\n",
    "    \n",
    "\n",
    "next(iter(train_dataloaders[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecSysModel(\n",
    "    n_users=len(lbl_user.classes_),\n",
    "    n_movies=len(lbl_movie.classes_)\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.8)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "train_loss_values = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    avg_train_loss = 0\n",
    "    for i, train_data in enumerate(train_dataloaders[epoch % NUM_SPLITS]):\n",
    "        users = train_data[\"users\"].to(device)\n",
    "        movies = train_data[\"movies\"].to(device)\n",
    "        ratings = train_data[\"ratings\"].to(device)\n",
    "        \n",
    "        output = model(users, movies)\n",
    "        \n",
    "        rating = ratings.view(28, -1).to(torch.float32)\n",
    "        \n",
    "        loss = loss_fn(output, rating)\n",
    "        avg_train_loss += loss.detach().cpu().numpy()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step()\n",
    "    avg_train_loss /= len(train_dataloaders[0])\n",
    "    print(f'Epoch {epoch}: {avg_train_loss}')\n",
    "    train_loss_values.append(avg_train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(obj=model.state_dict(), f=\"models/movielens_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f=\"models/movielens_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_loss_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_list = []\n",
    "target_rating_list = []\n",
    "\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.inference_mode():\n",
    "    for i, test_data in enumerate(test_dataloaders[0]):\n",
    "        users = test_data['users'].to(device)\n",
    "        movies = test_data['movies'].to(device)\n",
    "        ratings = test_data['ratings'].to(device)\n",
    "        \n",
    "        preds = model(users, movies)\n",
    "        \n",
    "        for i in range(BATCH_SIZE):\n",
    "            if round(preds[i].item()) == ratings[i]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "        \n",
    "        model_output_list.append(preds.sum().item() / len(users))\n",
    "        target_rating_list.append(ratings.sum().item() / len(users))\n",
    "        \n",
    "rms = mean_squared_error(target_rating_list, model_output_list, squared=False)\n",
    "print(f\"rms: {rms}\")\n",
    "print(f'Accuracy: {round(correct / total * 100, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_est_true = defaultdict(list)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for i, test_data in enumerate(test_dataloaders[0]):\n",
    "        users = test_data['users'].to(device)\n",
    "        movies = test_data['movies'].to(device)\n",
    "        ratings = test_data['ratings'].to(device)\n",
    "        \n",
    "        model_output = model(users, movies)\n",
    "        \n",
    "        for i in range(len(users)):\n",
    "            user_id = users[i].item()\n",
    "            movie_id = movies[i].item()\n",
    "            pred_rating = round(model_output[i][0].item())\n",
    "            true_rating = ratings[i].item()\n",
    "            \n",
    "            print(f'User {user_id} and Movie {movie_id}:')\n",
    "            print(f'Prediction: {pred_rating}, True: {true_rating}')\n",
    "            user_est_true[user_id].append((pred_rating, true_rating))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    \n",
    "    k = 100\n",
    "    threshold = 3.5\n",
    "    \n",
    "    for user_id, user_ratings in user_est_true.items():\n",
    "        \n",
    "        # sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        \n",
    "        # get the number of actual relevant item\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "        \n",
    "        # get the number of recommended items that are predicted relevant within topk\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "        \n",
    "        # get the number of recommended items that are actually relevant within topk\n",
    "        n_rel_and_rec_k = sum(\n",
    "            ((true_r >= threshold) and (est >= threshold))\n",
    "            for (est, true_r) in user_ratings[:k]\n",
    "        )\n",
    "        print(f'User {user_id}, n_rel {n_rel}, n_rec_k {n_rec_k}, n_rel_and_rec_k {n_rel_and_rec_k}')\n",
    "        \n",
    "        precisions[user_id] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "        recalls[user_id] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'precision at {k}: {sum(prec for prec in precisions.values()) / len(precisions)}')\n",
    "print(f'recall @ {k}: {sum(rec for rec in recalls.values()) / len(recalls)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
