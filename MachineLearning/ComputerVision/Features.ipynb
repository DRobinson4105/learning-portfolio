{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torchvision.transforms.functional as cvF\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"img2.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((256, 256)),\n",
    "])\n",
    "\n",
    "image = transform(img).to(device).unsqueeze(0)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "Examples of Using Features\n",
    "1. Matching - Extract features from two different images to compare them rather than pixel comparison\n",
    "2. Structure from Motion - Use features from many images to construct something that has been identified from those images from different viewpoints\n",
    "\n",
    "## Interest Points\n",
    "Points in an image that can be detected and are relevant for higher level processing\n",
    "Often used in applications like image stabilization and structure from motion\n",
    "Applications\n",
    "    - Key-Point Matching\n",
    "        1. Find a set of distinctive key-points\n",
    "        2. Define a region around each key-point\n",
    "        3. Extract and normalize the region content\n",
    "        4. Compute a local descriptor from the normalized region\n",
    "        5. Match local descriptors\n",
    "### Possible Approaches\n",
    "Corner Detection\n",
    "- Recognize corners by looking at a small region.\n",
    "    - \"Flat\" if no change in intensity in all directions\n",
    "    - \"Edge\" if no change in intensity along edge direction\n",
    "    - \"Corner\" if significant change in intensity in all directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harris Corner Detection\n",
    "$$E(u, v)=\\sum_{x,y}w(x, y)[I(x+u, y+v)-I(x, y)]^2$$\n",
    "1. Compute $M$ matrix for each window to recover a *cornerness* score $C$.\n",
    "2. Threshold to find pixels which give large corner response\n",
    "3. Find the local maximima pixels (non-maximum suppresion)\n",
    "\n",
    "Steps:\n",
    "1. Compute image gradients\n",
    "2. Compute $M$ components as squares of derivatives\n",
    "3. Gaussian filter with width $s$: $g(I_x^2), g(I_y^2), g(I_x\\circ I_y)$\n",
    "4. Compute cornerness $C = det(M)-\\alpha trace(M)^2=g(I_x^2)\\circ g(I_y^2)-g(I_x\\circ I_y)^2-\\alpha[g(I_x^2)+g(I_y^2)]^2$\n",
    "5. Threshold on $C$ to filter for high cornerness\n",
    "6. Non-maximal suppression to pick peak corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradients(image: torch.Tensor):\n",
    "    dx_kernel = torch.tensor(\n",
    "        [[1, 0, -1], [2, 0, -2], [1, 0, -1]], \n",
    "        device=device, dtype=torch.float\n",
    "    ).view(1, 1, 3, 3)\n",
    "\n",
    "    dy_kernel = torch.tensor(\n",
    "        [[1, 2, 1], [0, 0, 0], [-1, -2, -1]],\n",
    "        device=device, dtype=torch.float\n",
    "    ).view(1, 1, 3, 3)\n",
    "\n",
    "    grad_x = F.conv2d(image, dx_kernel, padding=1)\n",
    "    grad_y = F.conv2d(image, dy_kernel, padding=1)\n",
    "\n",
    "    return grad_x, grad_y\n",
    "\n",
    "def non_maximum_suppression(C, corners, radius):\n",
    "    dilated = F.max_pool2d(C, kernel_size=(radius*2+1, radius*2+1), stride=1, padding=radius)\n",
    "    local_max = (C == dilated.squeeze())\n",
    "    return corners & local_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.04\n",
    "threshold = 0.01\n",
    "\n",
    "# Compute image gradients\n",
    "grad_x, grad_y = compute_gradients(image)\n",
    "\n",
    "# Compute products of gradients\n",
    "Ixx = grad_x ** 2\n",
    "Iyy = grad_y ** 2\n",
    "Ixy = grad_x * grad_y\n",
    "\n",
    "# Smooth products of gradients with gaussian filter\n",
    "Ixx = cvF.gaussian_blur(Ixx, 5, 1.5)\n",
    "Iyy = cvF.gaussian_blur(Iyy, 5, 1.5)\n",
    "Ixy = cvF.gaussian_blur(Ixy, 5, 1.5)\n",
    "\n",
    "# Compute cornerness\n",
    "det_M = Ixx * Iyy - Ixy ** 2\n",
    "trace_M = Ixx + Iyy\n",
    "C = det_M - alpha * (trace_M ** 2)\n",
    "\n",
    "# Threshold on C to filter for high cornerness\n",
    "corners = C > threshold * C.max()\n",
    "\n",
    "corners = non_maximum_suppression(C, corners, 3)\n",
    "\n",
    "# Mark corners\n",
    "corner_image = image.cpu().numpy()\n",
    "corner_image[corners.cpu()] = 255\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Harris Corner Detection\")\n",
    "plt.imshow(corner_image.squeeze(), cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histograms of Oriented Gradients\n",
    "1. Extract a square window (block) of some size\n",
    "2. Divide block into a square grid of sub-blocks (cells)\n",
    "3. Compute orientation histogram of each cell\n",
    "4. Concatenate the histograms together\n",
    "5. Normalize $v$ (the concatenation of the histograms)\n",
    "    - Option 1: Divide $v$ by its Euclidean norm\n",
    "    - Option 2: Divide $v$ by its $L_1$ norm (sum of all absolute values of $v$)\n",
    "    - Option 3:\n",
    "        - Divide $v$ by its Euclidean norm\n",
    "        - Clip any value over 0.2\n",
    "        - Divide the resulting $v$ by its Euclidean norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale Invariant Feature Transform (SIFT)\n",
    "1. Scale-Space Extrema Detection - Search over multiple scales and image locations\n",
    "2. Key-Point Localization - Fit a model to determine location and scale, then select key-points based on a measure of stability\n",
    "3. Orientation Assignment - Compute best orientations for each key-point region\n",
    "4. Key-Point Description - Use local image gradients at selected scale and rotation to describe each key-point region\n",
    "\n",
    "Automatic Scale Selection\n",
    "- Function responses for increasing scale (map different scales to the function results and the highest function result has the best scale)\n",
    "- Function can be 2nd derivative of Gaussian (Laplacian of Gaussian)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
