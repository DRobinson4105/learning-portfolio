{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torchvision.transforms.functional as cvF\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_noise(image_tensor: torch.Tensor, mean=0.0, std=0.1):\n",
    "    noise = torch.randn(image_tensor.size(), device=device) * std + mean\n",
    "    noisy_image = image_tensor + noise\n",
    "    \n",
    "    return torch.clamp(noisy_image, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"img1.png\")\n",
    "\n",
    "image_tensor = transforms.Grayscale()(transforms.ToTensor()(image)[0:3]).to(device).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, height, width = image_tensor.shape\n",
    "\n",
    "y_pos = height // 2 + 50\n",
    "\n",
    "cv_image = cv2.imread('img1.png')\n",
    "cv_image = cv2.line(cv_image, (0, y_pos), (width, y_pos), (255, 0, 0), 2)\n",
    "\n",
    "plt.imshow(cv_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Intensity Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intensity_profile(image_tensor: torch.Tensor, y_pos: int):\n",
    "    line = image_tensor[0][0][y_pos]\n",
    "    y = line.cpu().numpy()\n",
    "    x = np.linspace(0, len(y)-1, len(y))\n",
    "\n",
    "    d_kernel = torch.tensor([-1, 1], device=device, dtype=torch.float)\n",
    "    dy = F.conv1d(image_tensor[0][0][y_pos].unsqueeze(0), d_kernel.unsqueeze(0).unsqueeze(0))\n",
    "    dy = F.pad(dy, (0, 1), mode='constant', value=0)\n",
    "    dy = dy.squeeze().cpu().numpy()\n",
    "\n",
    "    return x, y, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, dy = intensity_profile(image_tensor, y_pos)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x, y)\n",
    "plt.title('Intensity')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x, dy, color='r')\n",
    "plt.title('Intensity Derivative')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Gaussian Noise and Smooth for Intensity Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_image_tensor = gaussian_noise(image_tensor)\n",
    "x, y, dy = intensity_profile(noisy_image_tensor, y_pos)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x, y)\n",
    "plt.title('Intensity')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x, dy, color='r')\n",
    "plt.title('Intensity Derivative')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_noisy_image_tensor = cvF.gaussian_blur(noisy_image_tensor, kernel_size=5, sigma=2)\n",
    "x, y, dy = intensity_profile(smoothed_noisy_image_tensor, y_pos)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x, y)\n",
    "plt.title('Intensity')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x, dy, color='r')\n",
    "plt.title('Intensity Derivative')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prewitt Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_x = torch.tensor([[1, 0, -1],\n",
    "                       [1, 0, -1],\n",
    "                       [1, 0, -1]], dtype=torch.float, device=device)\n",
    "kernel_y = torch.tensor([[1, 1, 1],\n",
    "                       [0, 0, 0],\n",
    "                       [-1, -1, -1]], dtype=torch.float, device=device)\n",
    "\n",
    "edges_x = F.conv2d(image_tensor, kernel_x.view(1, 1, 3, 3))\n",
    "edges_y = F.conv2d(image_tensor, kernel_y.view(1, 1, 3, 3))\n",
    "edges = torch.sqrt(edges_x ** 2 + edges_y ** 2)\n",
    "\n",
    "edges = F.threshold(edges, 0.3, 0)\n",
    "\n",
    "edges_x = edges_x.squeeze().cpu().numpy()\n",
    "edges_y = edges_y.squeeze().cpu().numpy()\n",
    "edges = edges.squeeze().cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(edges_x, cmap='gray')\n",
    "plt.title('Horizontal Derivative')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(edges_y, cmap='gray')\n",
    "plt.title('Vertical Derivative')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(edges, cmap='gray')\n",
    "plt.title('Prewitt Edge Detection')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobel Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_x = torch.tensor([[1, 0, -1],\n",
    "                       [2, 0, -2],\n",
    "                       [1, 0, -1]], dtype=torch.float, device=device)\n",
    "kernel_y = torch.tensor([[1, 2, 1],\n",
    "                       [0, 0, 0],\n",
    "                       [-1, -2, -1]], dtype=torch.float, device=device)\n",
    "\n",
    "edges_x = F.conv2d(image_tensor, kernel_x.view(1, 1, 3, 3))\n",
    "edges_y = F.conv2d(image_tensor, kernel_y.view(1, 1, 3, 3))\n",
    "edges = torch.sqrt(edges_x ** 2 + edges_y ** 2)\n",
    "\n",
    "edges = F.threshold(edges, 0.3, 0)\n",
    "\n",
    "edges_x = edges_x.squeeze().cpu().numpy()\n",
    "edges_y = edges_y.squeeze().cpu().numpy()\n",
    "edges = edges.squeeze().cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(edges_x, cmap='gray')\n",
    "plt.title('Horizontal Derivative')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(edges_y, cmap='gray')\n",
    "plt.title('Vertical Derivative')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(edges, cmap='gray')\n",
    "plt.title('Sobel Edge Detection')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marr Hildreth Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacian_of_gaussian(image_tensor: torch.Tensor, kernel_size: int, sigma: float) -> torch.Tensor:\n",
    "    # Apply Gaussian smoothing\n",
    "    smoothed_image_tensor = cvF.gaussian_blur(image_tensor, kernel_size, sigma)\n",
    "\n",
    "    # Apply Laplacian of Gaussian\n",
    "    x = torch.arange(kernel_size, dtype=torch.float, device=device) - kernel_size // 2\n",
    "    y = torch.arange(kernel_size, dtype=torch.float, device=device) - kernel_size // 2\n",
    "    x, y = torch.meshgrid(x, y)\n",
    "    normalization = 1 / (2.0 * np.pi * sigma**2)\n",
    "    log_kernel = normalization * ((x**2 + y**2 - 2.0 * sigma**2) / (sigma**4)) * torch.exp(-(x**2 + y**2) / (2.0 * sigma**2))\n",
    "    log_kernel = log_kernel - log_kernel.mean()\n",
    "    log_kernel = log_kernel.unsqueeze(0).unsqueeze(0)\n",
    "    log_image_tensor = F.conv2d(smoothed_image_tensor, log_kernel, padding=kernel_size // 2)\n",
    "\n",
    "    return log_image_tensor.squeeze(0)\n",
    "\n",
    "def zero_crossing(log_image_tensor):\n",
    "    zero_crossings = torch.zeros_like(log_image_tensor)\n",
    "    zero_crossings[:, 1:-1, 1:-1] = (\n",
    "        (log_image_tensor[:, 1:-1, 1:-1] * log_image_tensor[:, :-2, 1:-1] < 0) |\n",
    "        (log_image_tensor[:, 1:-1, 1:-1] * log_image_tensor[:, 2:, 1:-1] < 0) |\n",
    "        (log_image_tensor[:, 1:-1, 1:-1] * log_image_tensor[:, 1:-1, :-2] < 0) |\n",
    "        (log_image_tensor[:, 1:-1, 1:-1] * log_image_tensor[:, 1:-1, 2:] < 0)\n",
    "    ).float()\n",
    "\n",
    "    return zero_crossings.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_image_tensor = cvF.gaussian_blur(image_tensor, kernel_size=5, sigma=1)\n",
    "log_image_tensor = laplacian_of_gaussian(smoothed_image_tensor, 5, 1)\n",
    "edges = zero_crossing(log_image_tensor)\n",
    "\n",
    "log_image = log_image_tensor.squeeze(0).cpu().numpy()\n",
    "edges = edges.squeeze(0).cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Image after LoG\")\n",
    "plt.imshow(log_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Marr Hildreth Edge Detection\")\n",
    "plt.imshow(edges, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canny Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradients(image_tensor):\n",
    "    kernel_x = torch.tensor([[1, 0, -1],\n",
    "                       [2, 0, -2],\n",
    "                       [1, 0, -1]], dtype=torch.float, device=device)\n",
    "    kernel_y = torch.tensor([[1, 2, 1],\n",
    "                        [0, 0, 0],\n",
    "                        [-1, -2, -1]], dtype=torch.float, device=device)\n",
    "\n",
    "    edges_x = F.conv2d(image_tensor, kernel_x.view(1, 1, 3, 3))\n",
    "    edges_y = F.conv2d(image_tensor, kernel_y.view(1, 1, 3, 3))\n",
    "    \n",
    "    edges = torch.sqrt(edges_x ** 2 + edges_y ** 2)\n",
    "    theta = torch.atan2(edges_y, edges_x)\n",
    "\n",
    "    return edges, theta\n",
    "\n",
    "def non_maximum_suppression(edges, theta):\n",
    "    theta = theta * 180.0 / np.pi\n",
    "    theta[theta < 0] += 180\n",
    "    \n",
    "    Z = torch.zeros_like(edges, device=device, dtype=torch.float)\n",
    "    angle = theta % 180\n",
    "    \n",
    "    mask_0 = ((angle >= 0) & (angle < 22.5)) | ((angle >= 157.5) & (angle < 180))\n",
    "    mask_45 = (angle >= 22.5) & (angle < 67.5)\n",
    "    mask_90 = (angle >= 67.5) & (angle < 112.5)\n",
    "    mask_135 = (angle >= 112.5) & (angle < 157.5)\n",
    "\n",
    "    P0 = edges[:, :, 1:-1, 2:] * mask_0[:, :, 1:-1, 1:-1] + edges[:, :, 1:-1, :-2] * mask_0[:, :, 1:-1, 1:-1]\n",
    "    P45 = edges[:, :, 2:, :-2] * mask_45[:, :, 1:-1, 1:-1] + edges[:, :, :-2, 2:] * mask_45[:, :, 1:-1, 1:-1]\n",
    "    P90 = edges[:, :, 2:, 1:-1] * mask_90[:, :, 1:-1, 1:-1] + edges[:, :, :-2, 1:-1] * mask_90[:, :, 1:-1, 1:-1]\n",
    "    P135 = edges[:, :, :-2, :-2] * mask_135[:, :, 1:-1, 1:-1] + edges[:, :, 2:, 2:] * mask_135[:, :, 1:-1, 1:-1]\n",
    "\n",
    "    Q = torch.max(torch.max(P0, P45), torch.max(P90, P135))\n",
    "\n",
    "    Z[:, :, 1:-1, 1:-1] = edges[:, :, 1:-1, 1:-1] * (edges[:, :, 1:-1, 1:-1] >= Q).float()\n",
    "    \n",
    "    return Z\n",
    "\n",
    "def threshold(image_tensor: torch.Tensor, low_threshold=0.05, high_threshold=0.15):\n",
    "    high_threshold = image_tensor.max() * high_threshold\n",
    "    low_threshold = high_threshold * low_threshold\n",
    "    \n",
    "    M, N = image_tensor.shape[2], image_tensor.shape[3]\n",
    "    res = torch.zeros_like(image_tensor, device=device, dtype=torch.float)\n",
    "    \n",
    "    strong = 255\n",
    "    weak = 25\n",
    "    \n",
    "    _, _, strong_i, strong_j = torch.where(image_tensor >= high_threshold)\n",
    "    _, _, zeros_i, zeros_j = torch.where(image_tensor < low_threshold)\n",
    "    \n",
    "    _, _, weak_i, weak_j = torch.where((image_tensor <= high_threshold) & (image_tensor >= low_threshold))\n",
    "    \n",
    "    res[0][0][strong_i, strong_j] = strong\n",
    "    res[0][0][weak_i, weak_j] = weak\n",
    "    \n",
    "    return res\n",
    "\n",
    "def hysteresis(image_tensor: torch.Tensor):\n",
    "    M, N = image_tensor.shape[2], image_tensor.shape[3]\n",
    "    weak = 25\n",
    "    strong = 255\n",
    "\n",
    "    _, _, strong_i, strong_j = torch.where(image_tensor == strong)\n",
    "    _, _, weak_i, weak_j = torch.where(image_tensor == weak)\n",
    "    \n",
    "    strong_pixels = set(zip(strong_i.tolist(), strong_j.tolist()))\n",
    "    weak_pixels = set(zip(weak_i.tolist(), weak_j.tolist()))\n",
    "    \n",
    "    while strong_pixels:\n",
    "        i, j = strong_pixels.pop()\n",
    "        for di in [-1, 0, 1]:\n",
    "            for dj in [-1, 0, 1]:\n",
    "                ni, nj = i + di, j + dj\n",
    "                if (di != 0 or dj != 0) and (0 <= ni < M) and (0 <= nj < N):\n",
    "                    if (ni, nj) in weak_pixels:\n",
    "                        image_tensor[0, 0, ni, nj] = strong\n",
    "                        strong_pixels.add((ni, nj))\n",
    "                        weak_pixels.remove((ni, nj))\n",
    "    \n",
    "    image_tensor[image_tensor == weak] = 0\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Gaussian blur to smooth image\n",
    "smoothed_image_tensor = cvF.gaussian_blur(image_tensor, kernel_size=5, sigma=1)\n",
    "\n",
    "# Compute gradients\n",
    "edges, theta = gradients(image_tensor)\n",
    "\n",
    "# Non-Maximum Suppression\n",
    "non_maximum_suppressed_image_tensor = non_maximum_suppression(edges, theta)\n",
    "\n",
    "# Thresholding\n",
    "thresholded_image_tensor = threshold(non_maximum_suppressed_image_tensor)\n",
    "\n",
    "# Edge Tracking with Hysteresis\n",
    "edges = hysteresis(thresholded_image_tensor)\n",
    "\n",
    "non_maximum_suppressed_image_tensor = non_maximum_suppressed_image_tensor.squeeze(0).squeeze(0).cpu().numpy()\n",
    "thresholded_image_tensor = thresholded_image_tensor.squeeze(0).squeeze(0).cpu().numpy()\n",
    "edges = edges.squeeze(0).squeeze(0).cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.title(\"Non-Maximum Suppression\")\n",
    "plt.imshow(non_maximum_suppressed_image_tensor, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.title(\"Thresholding\")\n",
    "plt.imshow(thresholded_image_tensor, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.title(\"Canny Edge Detection\")\n",
    "plt.imshow(edges, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
