{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torchvision.transforms.functional as cvF\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_noise(image_tensor: torch.Tensor, mean=0.0, std=0.1):\n",
    "    noise = torch.randn(image_tensor.size(), device=device) * std + mean\n",
    "    noisy_image = image_tensor + noise\n",
    "    \n",
    "    return torch.clamp(noisy_image, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"img1.png\")\n",
    "image = transforms.ToTensor()(image)[0:3]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.Grayscale()\n",
    "])\n",
    "\n",
    "image = transform(image).to(device).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, height, width = image.shape\n",
    "\n",
    "y_pos = height // 2 +25\n",
    "\n",
    "cv_image = cv2.resize(cv2.imread('img1.png'), (256, 256))\n",
    "cv_image = cv2.line(cv_image, (0, y_pos), (width, y_pos), (255, 0, 0), 2)\n",
    "\n",
    "plt.imshow(cv_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Intensity Profile\n",
    "\n",
    "The intensity graph displays how light or dark each pixel is in a grayscale image. By taking the derivative of that graph, all of the peaks and valleys are edges from a group of light pixels to a group of dark pixels or vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intensity_profile(image_tensor: torch.Tensor, y_pos: int):\n",
    "    line = image_tensor[0][0][y_pos]\n",
    "    y = line.cpu().numpy()\n",
    "    x = np.linspace(0, len(y)-1, len(y))\n",
    "\n",
    "    d_kernel = torch.tensor([-1, 1], device=device, dtype=torch.float)\n",
    "    dy = F.conv1d(image_tensor[0][0][y_pos].unsqueeze(0), d_kernel.unsqueeze(0).unsqueeze(0))\n",
    "    dy = F.pad(dy, (0, 1), mode='constant', value=0)\n",
    "    dy = dy.squeeze().cpu().numpy()\n",
    "\n",
    "    return x, y, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, dy = intensity_profile(image, y_pos)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x, y)\n",
    "plt.title('Intensity')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x, dy, color='r')\n",
    "plt.title('Intensity Derivative')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding noise to the image can make it harder to identify the edges from the intensity profile since there are more drastic changes from light to dark and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_image_tensor = gaussian_noise(image)\n",
    "x, y, dy = intensity_profile(noisy_image_tensor, y_pos)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x, y)\n",
    "plt.title('Intensity')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x, dy, color='r')\n",
    "plt.title('Intensity Derivative')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By applying a gaussian filter to smooth the image, the noise can be removed and the resulting intensity profile not only shows the edges again but looks very similar to the starting intensity profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_noisy_image_tensor = cvF.gaussian_blur(noisy_image_tensor, kernel_size=5, sigma=2)\n",
    "x, y, dy = intensity_profile(smoothed_noisy_image_tensor, y_pos)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x, y)\n",
    "plt.title('Intensity')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x, dy, color='r')\n",
    "plt.title('Intensity Derivative')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 1, 1], [1, 1, 1], [1, 1, 1]])\n",
    "y = torch.tensor([1, 0, -1])\n",
    "\n",
    "x * y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prewitt Edge Detection\n",
    "\n",
    "Edges in $x$ direction\n",
    "1. Smooth the image with a convolution with kernel, $\\begin{bmatrix} 1 & 1 & 1 \\\\ 1 & 1 & 1 \\\\ 1 & 1 & 1 \\end{bmatrix}$\n",
    "2. Apply derivative in $x$ direction with a convolution with kernel, $\\begin{bmatrix} 1 & 0 & -1 \\end{bmatrix}$\n",
    "\n",
    "Edges in $y$ direction\n",
    "1. Smooth the image with a convolution with kernel, $\\begin{bmatrix} 1 & 1 & 1 \\\\ 1 & 1 & 1 \\\\ 1 & 1 & 1 \\end{bmatrix}$\n",
    "2. Apply derivative in $y$ direction with a convolution with kernel, $\\begin{bmatrix} 1 \\\\ 0 \\\\ -1 \\end{bmatrix}$\n",
    "\n",
    "Hadamard product can be used to combine the two steps.\n",
    "\n",
    "The gradient (edge) magnitude can be found with the equation: $edges = \\sqrt{edges_x^2 + edges_y^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_x = torch.tensor(\n",
    "    [[1, 0, -1], [1, 0, -1], [1, 0, -1]],\n",
    "    dtype=torch.float, device=device\n",
    ").view(1, 1, 3, 3)\n",
    "kernel_y = torch.tensor(\n",
    "    [[1, 1, 1], [0, 0, 0], [-1, -1, -1]],\n",
    "    dtype=torch.float, device=device\n",
    ").view(1, 1, 3, 3)\n",
    "\n",
    "edges_x = F.conv2d(image, kernel_x)\n",
    "edges_y = F.conv2d(image, kernel_y)\n",
    "edges = torch.sqrt(edges_x ** 2 + edges_y ** 2)\n",
    "\n",
    "edges = F.threshold(edges, 0.3, 0)\n",
    "\n",
    "edges_x = edges_x.squeeze().cpu().numpy()\n",
    "edges_y = edges_y.squeeze().cpu().numpy()\n",
    "edges = edges.squeeze().cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(image.squeeze().cpu().numpy(), cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(edges_x, cmap='gray')\n",
    "plt.title('Horizontal Derivative')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(edges_y, cmap='gray')\n",
    "plt.title('Vertical Derivative')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(edges, cmap='gray')\n",
    "plt.title('Prewitt Edge Detection')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobel Edge Detection\n",
    "\n",
    "Edges in $x$ direction\n",
    "1. Smooth the image with a convolution with kernel, $\\begin{bmatrix} 1 & 1 & 1 \\\\ 2 & 2 & 2 \\\\ 1 & 1 & 1 \\end{bmatrix}$\n",
    "2. Apply derivative in $x$ direction with a convolution with kernel, $\\begin{bmatrix} 1 & 0 & -1 \\end{bmatrix}$\n",
    "\n",
    "Edges in $y$ direction\n",
    "1. Smooth the image with a convolution with kernel, $\\begin{bmatrix} 1 & 2 & 1 \\\\ 1 & 2 & 1 \\\\ 1 & 2 & 1 \\end{bmatrix}$\n",
    "2. Apply derivative in $y$ direction with a convolution with kernel, $\\begin{bmatrix} 1 \\\\ 0 \\\\ -1 \\end{bmatrix}$\n",
    "\n",
    "Hadamard product can be used to combine the two steps.\n",
    "\n",
    "The gradient (edge) magnitude can be found with the following equation\n",
    "$$edges = \\sqrt{edges_x^2 + edges_y^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_x = torch.tensor([[1, 0, -1],\n",
    "                       [2, 0, -2],\n",
    "                       [1, 0, -1]], dtype=torch.float, device=device)\n",
    "kernel_y = torch.tensor([[1, 2, 1],\n",
    "                       [0, 0, 0],\n",
    "                       [-1, -2, -1]], dtype=torch.float, device=device)\n",
    "\n",
    "edges_x = F.conv2d(image, kernel_x.view(1, 1, 3, 3))\n",
    "edges_y = F.conv2d(image, kernel_y.view(1, 1, 3, 3))\n",
    "edges = torch.sqrt(edges_x ** 2 + edges_y ** 2)\n",
    "\n",
    "edges = F.threshold(edges, 0.3, 0)\n",
    "\n",
    "edges_x = edges_x.squeeze().cpu().numpy()\n",
    "edges_y = edges_y.squeeze().cpu().numpy()\n",
    "edges = edges.squeeze().cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(image.squeeze().cpu().numpy(), cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(edges_x, cmap='gray')\n",
    "plt.title('Horizontal Derivative')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(edges_y, cmap='gray')\n",
    "plt.title('Vertical Derivative')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(edges, cmap='gray')\n",
    "plt.title('Sobel Edge Detection')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marr Hildreth Edge Detection\n",
    "\n",
    "1. Smooth image with Gaussian filter\n",
    "2. Apply Laplacian of Gaussian (LoG)\n",
    "$$\\Delta ^2 g(x, y)=-\\frac{1}{\\sqrt{2\\pi}\\sigma ^3}\\Big( 2-\\frac{x^2+y^2}{\\sigma ^2} \\Big)e^{-\\frac{x^2+y^2}{2\\sigma ^2}}$$\n",
    "3. Find zery crossings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacian_of_gaussian(image_tensor: torch.Tensor, kernel_size: int, sigma: float) -> torch.Tensor:\n",
    "    # Apply Gaussian smoothing\n",
    "    smoothed_image_tensor = cvF.gaussian_blur(image_tensor, kernel_size, sigma)\n",
    "\n",
    "    # Apply Laplacian of Gaussian\n",
    "    x = torch.arange(kernel_size, dtype=torch.float, device=device) - kernel_size // 2\n",
    "    y = torch.arange(kernel_size, dtype=torch.float, device=device) - kernel_size // 2\n",
    "    x, y = torch.meshgrid(x, y)\n",
    "    normalization = 1 / (2.0 * np.pi * sigma**2)\n",
    "    log_kernel = normalization * ((x**2 + y**2 - 2.0 * sigma**2) / (sigma**4)) * torch.exp(-(x**2 + y**2) / (2.0 * sigma**2))\n",
    "    log_kernel = log_kernel - log_kernel.mean()\n",
    "    log_kernel = log_kernel.unsqueeze(0).unsqueeze(0)\n",
    "    log_image_tensor = F.conv2d(smoothed_image_tensor, log_kernel, padding=kernel_size // 2)\n",
    "\n",
    "    return log_image_tensor.squeeze(0)\n",
    "\n",
    "def zero_crossing(log_image_tensor):\n",
    "    zero_crossings = torch.zeros_like(log_image_tensor)\n",
    "    zero_crossings[:, 1:-1, 1:-1] = (\n",
    "        (log_image_tensor[:, 1:-1, 1:-1] * log_image_tensor[:, :-2, 1:-1] < 0) |\n",
    "        (log_image_tensor[:, 1:-1, 1:-1] * log_image_tensor[:, 2:, 1:-1] < 0) |\n",
    "        (log_image_tensor[:, 1:-1, 1:-1] * log_image_tensor[:, 1:-1, :-2] < 0) |\n",
    "        (log_image_tensor[:, 1:-1, 1:-1] * log_image_tensor[:, 1:-1, 2:] < 0)\n",
    "    ).float()\n",
    "\n",
    "    return zero_crossings.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_image_tensor = cvF.gaussian_blur(image, kernel_size=5, sigma=1)\n",
    "log_image_tensor = laplacian_of_gaussian(smoothed_image_tensor, 5, 1)\n",
    "edges = zero_crossing(log_image_tensor)\n",
    "\n",
    "log_image = log_image_tensor.squeeze(0).cpu().numpy()\n",
    "edges = edges.squeeze(0).cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(image.squeeze().cpu().numpy(), cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Image after LoG\")\n",
    "plt.imshow(log_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Marr Hildreth Edge Detection\")\n",
    "plt.imshow(edges, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canny Edge Detection\n",
    "\n",
    "1. Smooth image with Gaussian filter\n",
    "2. Compute gradiant magnitude and orientation\n",
    "3. Apply non-max suppression\n",
    "4. Apply thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradients(image):\n",
    "    kernel_x = torch.tensor(\n",
    "        [[1, 0, -1], [2, 0, -2], [1, 0, -1]], \n",
    "        dtype=torch.float, device=device\n",
    "    ).view(1, 1, 3, 3)\n",
    "    kernel_y = torch.tensor(\n",
    "        [[1, 2, 1], [0, 0, 0], [-1, -2, -1]],\n",
    "        dtype=torch.float, device=device\n",
    "    ).view(1, 1, 3, 3)\n",
    "\n",
    "    # Compute gradients in x and y direction\n",
    "    grad_x = F.conv2d(image, kernel_x, padding=1)\n",
    "    grad_y = F.conv2d(image, kernel_y, padding=1)\n",
    "    \n",
    "    return grad_x, grad_y\n",
    "\n",
    "def non_max_suppression(edges, theta):\n",
    "    theta = theta * 180.0 / np.pi\n",
    "    theta[theta < 0] += 180\n",
    "    theta = torch.remainder(theta, 180.0)\n",
    "\n",
    "    Z = torch.zeros_like(edges, device=device, dtype=torch.float)\n",
    "    \n",
    "    # Define the direction ranges and neighbor offsets\n",
    "    direction_ranges = [(0, 22.5), (22.5, 67.5), (67.5, 112.5), (112.5, 157.5), (157.5, 180)]\n",
    "    neighbor_offsets = [((0, 1), (0, -1)),\n",
    "                        ((1, 1), (-1, -1)),\n",
    "                        ((1, 0), (-1, 0)),\n",
    "                        ((-1, 1), (1, -1)),\n",
    "                        ((0, 1), (0, -1))]\n",
    "    \n",
    "    edges = edges.squeeze()\n",
    "    theta = theta.squeeze()\n",
    "    \n",
    "    # Pad edges for boundary edges\n",
    "    padded_edges = F.pad(edges, (1, 1, 1, 1), mode='constant', value=0)\n",
    "    \n",
    "    # Iterate over direction ranges and neighbor offsets\n",
    "    for (lb, ub), (offset1, offset2) in zip(direction_ranges, neighbor_offsets):\n",
    "        mask = (theta >= lb) & (theta < ub)\n",
    "        \n",
    "        i_off1, j_off1 = offset1\n",
    "        i_off2, j_off2 = offset2\n",
    "        \n",
    "        neighbor1 = padded_edges[1+i_off1:1+i_off1+edges.size(0), 1+j_off1:1+j_off1+edges.size(1)]\n",
    "        neighbor2 = padded_edges[1+i_off2:1+i_off2+edges.size(0), 1+j_off2:1+j_off2+edges.size(1)]\n",
    "        \n",
    "        edge_mask = (edges >= neighbor1) & (edges >= neighbor2)\n",
    "        combined_mask = mask & edge_mask\n",
    "        \n",
    "        Z[combined_mask.unsqueeze(0).unsqueeze(0)] = edges[combined_mask]\n",
    "\n",
    "    return Z\n",
    "\n",
    "def threshold_and_hysteresis(image: torch.Tensor, low_threshold=0.05, high_threshold=0.15):\n",
    "    low = image > low_threshold\n",
    "    high = image > high_threshold\n",
    "\n",
    "    image = low * 0.5 + high * 0.5\n",
    "\n",
    "    hysteresis_kernel = torch.ones((3, 3), device=device, dtype=torch.float).view(1, 1, 3, 3) + 0.25\n",
    "\n",
    "    weak = (image == 0.5) * 1\n",
    "    weak_is_high = (F.conv2d(image, hysteresis_kernel, padding=1) > 1) * weak\n",
    "    image = high * 1 + weak_is_high * 1\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image.shape)\n",
    "\n",
    "# Apply Gaussian blur to smooth image\n",
    "smoothed_image = cvF.gaussian_blur(image, kernel_size=5, sigma=1)\n",
    "\n",
    "# Compute gradient magnitude and orientation\n",
    "grad_x, grad_y = compute_gradients(image)\n",
    "\n",
    "grad = torch.sqrt(grad_x ** 2 + grad_y ** 2)\n",
    "theta = torch.atan2(grad_y, grad_x)\n",
    "grad = grad / grad.max()\n",
    "\n",
    "# Non-Maximum Suppression\n",
    "non_max_suppressed_image = non_max_suppression(grad, theta)\n",
    "\n",
    "# Thresholding\n",
    "thresholded_image = threshold_and_hysteresis(non_max_suppressed_image)\n",
    "\n",
    "non_max_suppressed_image = non_max_suppressed_image.squeeze().cpu().numpy()\n",
    "grad = grad.squeeze().cpu().numpy()\n",
    "thresholded_image = thresholded_image.squeeze().cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(image.squeeze().cpu().numpy(), cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.title(\"Gradients\")\n",
    "plt.imshow(grad, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.title(\"Non-Maximum Suppression\")\n",
    "plt.imshow(non_max_suppressed_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.title(\"Thresholding\")\n",
    "plt.imshow(thresholded_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
