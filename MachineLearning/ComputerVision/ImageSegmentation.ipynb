{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm as notebook_tqdm\n",
    "from torchvision.datasets import VOCSegmentation\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Segmentation\n",
    "Image segmentation partitions an image into regions called segments and creates segments by analyzing some similarity criteria (such as intensity, color, texture, histogram, or features).\n",
    "\n",
    "### Image Segmentation Methods\n",
    "- Thresholding (binarization, otsu)\n",
    "- Region-based (region growing, region splitting)\n",
    "- Clustering (k-means, mean-shift)\n",
    "- Graph-based (graph-cut, random walk)\n",
    "- Shape-based (level set, active contours)\n",
    "- Energy minimization (MRF)\n",
    "- Machine Learning-based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threshold\n",
    "### Binarization\n",
    "Image binarization applies often just one global threshold $T$ for mapping a scalar image $I$ into a binary image with black and white. The global threshold can be identified by an optimization strategy aiming at creating \"large\" connected regions and reducing the number of small-sized regions, called *artifacts*.\n",
    "\n",
    "Useful for when the histogram of the intensity levels has a valley where there is not many pixels at the threshold and there are peaks on the left and right of the threshold, representing the darker and brighter objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"img3.png\", cv2.IMREAD_GRAYSCALE)\n",
    "image = cv2.resize(image, (512, 512))\n",
    "image = torch.from_numpy(image).to(device=device, dtype=torch.float).unsqueeze(0)\n",
    "\n",
    "binarized_image = image > 150\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(image.squeeze().cpu().numpy(), bins=10, range=(0, 256))\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(binarized_image.squeeze().cpu().numpy(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otsu\n",
    "Otsu uses grey-value histogram of the given image $I$ as input and aims at providing the best threshold\n",
    "Otsu's algorithm selects a threshold that maximizes the between-class variance $\\sigma_b^2$.\n",
    "\n",
    "For example, with two classes, $\\sigma_b^2=P_1(\\mu_1-\\mu)^2+P_2(\\mu_2-\\mu)^2=P_1P_2(\\mu_1-\\mu_2)^2$ where $P_1$ and $P_2$ are the class probabilities, and $\\mu_i$ is the means of object and background classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variance(image: torch.Tensor, threshold):\n",
    "    # Calculate between-class variance with the previous formula\n",
    "    binarized_image = image > threshold\n",
    "    P1 = binarized_image.nonzero().shape[0] / image.flatten().shape[0]\n",
    "    P2 = 1 - P1\n",
    "    mu1 = image[image > threshold]\n",
    "    mu1 = 0 if mu1.shape[0] == 0 else mu1.mean()\n",
    "    mu2 = image[image <= threshold]\n",
    "    mu2 = 0 if mu2.shape[0] == 0 else mu2.mean()\n",
    "    return P1 * P2 * (mu1 - mu2) ** 2\n",
    "\n",
    "best_threshold = -1\n",
    "best_variance = -1\n",
    "\n",
    "# Test every integer threshold value to determine threshold with highest between-class variance\n",
    "for threshold in range(0, 256):\n",
    "    variance = get_variance(image, threshold)\n",
    "    \n",
    "    if variance > best_variance:\n",
    "        best_variance = variance\n",
    "        best_threshold = threshold\n",
    "\n",
    "plt.imshow((image > best_threshold).squeeze().cpu().numpy(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Region-based Methods\n",
    "### Region Growing\n",
    "To build a segment, start at one *seed pixel* and recursively add adjacent pixels that satisfy a \"similarity criterion\" with the pixels already included.\n",
    "\n",
    "Similarity Criterion:\n",
    "1. The absolute difference between a candidate pixel and the seed pixel must lie within a specified range\n",
    "2. The absolute intensity difference between a candidate pixel and the running average intensity of the growing region must lie within a specified range\n",
    "3. The difference between the standard deviation in intensity over a specified local neighborhood of the candidate pixel and that over a local neighborhood of the candidate pixel must exceed a certain threshold.\n",
    "\n",
    "### Region Splitting\n",
    "Start with the whole image as a single region and recursively divide it into sub-regions while a condition of homogeneity is not satisfied.\n",
    "\n",
    "Construct a region adjacency graph as a quadtree for splitting.\n",
    "\n",
    "Algorithm:\n",
    "1. If a region $R$ is inhomogeneous ($P(R)=FALSE$), then $R$ is split into four sub-regions and algorithm is ran on sub-regions\n",
    "2. If two adjacent regions $R_i$, $R_j$ are homogeneous ($P(R_i\\cup R_j)=TRUE$), they are merged\n",
    "3. The algorithm stops when no further splitting or merging is possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "### K-means\n",
    "Start with some initial cluster centers, one for each pre-defined category (try out multiple starting points since some seeds can result in poor convergence rate). Loop until none of the centers have changed in an iteration or until a counter is passed:\n",
    "1. Assign each example to the closest center\n",
    "2. Recalculate centers as the mean of the points in a cluster\n",
    "\n",
    "K-means tries to minimize the sum of the squared distances from each point to the associated cluster center.\n",
    "\n",
    "SLIC Algorithm\n",
    "1. Initialize cluster centers on pixel grid in steps, $S$\n",
    "2. Move centers to position in 3x3 window with smallest gradient\n",
    "3. Compare each pixel to cluster center within $2S$ pixel distance and assign to nearest\n",
    "4. Recompute cluster centers as mean color/position of pixels belonging to each cluster\n",
    "5. Repeat steps 3-4 until residual error is small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('img3.png', cv2.IMREAD_GRAYSCALE)\n",
    "image = cv2.resize(image, (1024, 1024))\n",
    "image = torch.from_numpy(image).to(device=device, dtype=torch.float)\n",
    "\n",
    "height, width = image.shape\n",
    "\n",
    "segmented_image = image.view((-1, 1))\n",
    "\n",
    "num_clusters = 3\n",
    "iterations = 100\n",
    "\n",
    "indices = torch.randperm(segmented_image.shape[0])[:num_clusters]\n",
    "centers = segmented_image[indices]\n",
    "\n",
    "for _ in range(iterations):\n",
    "    # Assign centers to each pixel\n",
    "    distances = torch.cdist(segmented_image.unsqueeze(0), centers.unsqueeze(0)).squeeze(0)\n",
    "    cluster_assignments = torch.argmin(distances, dim=1)\n",
    "\n",
    "    # Recalculate centers\n",
    "    new_centers = torch.zeros(num_clusters, device=device, dtype=torch.float)\n",
    "    \n",
    "    for i in range(num_clusters):\n",
    "        cluster_points = segmented_image[cluster_assignments == i]\n",
    "        new_center = cluster_points.mean() if cluster_points.numel() > 0 else torch.zeros((1), device=device, dtype=torch.float)\n",
    "        new_centers[i] = new_center\n",
    "    \n",
    "    new_centers = new_centers.view((num_clusters, 1))\n",
    "    if centers.equal(new_centers): break\n",
    "\n",
    "    centers = new_centers\n",
    "\n",
    "segmented_image = centers[cluster_assignments].view(1, height, width)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(image.squeeze().cpu().numpy(), cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Segmented Image')\n",
    "plt.imshow(segmented_image.squeeze().cpu().numpy(), cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean-Shift\n",
    "Attempts to find all possible cluster centers in feature space which resolves the issue with K-means where the number of clusters has to be pre-defined. The mean shift algorithm seeks local maximas of density in the feature space.\n",
    "\n",
    "1. Choose kernel and bandwidth\n",
    "2. For each point:\n",
    "    - Center a window on that point\n",
    "    - Compute the mean of the data in the search window\n",
    "    - Center the search window at the new mean location\n",
    "    - Repeat until window does not move anymore\n",
    "\n",
    "All of the points will be a part of the cluster that it has converged to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('img4.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "image = cv2.resize(image, (128, 128))\n",
    "image = torch.from_numpy(image).to(device=device, dtype=torch.float)\n",
    "\n",
    "radius = 35\n",
    "height, width, _ = image.shape\n",
    "epsilon = 0.1\n",
    "X = image.view(-1, 3)\n",
    "\n",
    "def mean_shift_step(X: torch.Tensor):\n",
    "    distances = torch.abs(torch.cdist(X, X))\n",
    "    neighbors = distances <= radius\n",
    "    neighbors = neighbors.unsqueeze(2).expand(-1, -1, 3)\n",
    "    weighted_neighbors = torch.where(neighbors, X, torch.full(X.shape, float('nan'), device=device))\n",
    "    means = torch.nanmean(weighted_neighbors, dim=1)\n",
    "    return means\n",
    "\n",
    "for i in range(100):\n",
    "    nX = mean_shift_step(X)\n",
    "\n",
    "    if (torch.abs(X - nX) < epsilon).all().item():\n",
    "        break\n",
    "\n",
    "    X = nX\n",
    "\n",
    "new_image = X.view(height, width, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = image.squeeze().cpu().numpy().reshape(-1, 3)\n",
    "new_pixels = new_image.squeeze().cpu().numpy().reshape(-1, 3)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(221, projection='3d')\n",
    "ax.scatter(pixels[:, 0], pixels[:, 1], pixels[:, 2], c=pixels/255.0, marker='o', alpha=0.6)\n",
    "ax.set_title('Original')\n",
    "\n",
    "ax = fig.add_subplot(222, projection='3d')\n",
    "ax.scatter(new_pixels[:, 0], new_pixels[:, 1], new_pixels[:, 2], c=new_pixels/255.0, marker='o', alpha=0.6, )\n",
    "ax.set_title('Mean Shift Clustering')\n",
    "\n",
    "ax = fig.add_subplot(223)\n",
    "ax.imshow(image.to(torch.uint8).squeeze().cpu().numpy())\n",
    "ax.axis('off')\n",
    "\n",
    "ax = fig.add_subplot(224)\n",
    "ax.imshow(new_image.to(torch.uint8).squeeze().cpu().numpy())\n",
    "ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segmentation\n",
    "Assigns a label to **each pixel** in an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling\n",
    "Used to reverse pooling layers\n",
    "\n",
    "Method: Bi-linear interpolation\n",
    "$$f(x, y) = \\frac{(x_2 - x)(y_2 - y)}{(x_2 - x_1)(y_2 - y_1)} f(x_1, y_1) + \\frac{(x - x_1)(y_2 - y)}{(x_2 - x_1)(y_2 - y_1)} f(x_2, y_1) + \\frac{(x_2 - x)(y - y_1)}{(x_2 - x_1)(y_2 - y_1)} f(x_1, y_2) + \\frac{(x - x_1)(y - y_1)}{(x_2 - x_1)(y_2 - y_1)} f(x_2, y_2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instance Segmentation\n",
    "Segment each instance of the same class separately."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
